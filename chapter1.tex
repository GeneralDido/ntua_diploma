\chapter{Εισαγωγή}

\section{Τί είναι η μηχανική μάθηση}

Η μηχανική μάθηση ή \textlatin{machine learning} αφορά μεθόδους με τις οποίες ένας υπολογιστής μπορεί να αποκτήσει γνώση για ένα σύνολο δεδομένων μετά από ανάλυση τους. Σε κάθε πρόβλημα το οποίο έχει τα εξής χαρακτηριστικα, η μηχανική μάθηση μπορεί να μας βοηθήσει να εξάγουμε χρήσιμα συμπεράσματα \citepri{Abu}:
\begin{itemize}
  \item Το πρόβλημα παρουσιάζει ένα μοτίβο
  \item Δεν μπορούμε να περιγράψουμε το μοτίβο αυτό με μαθηματικό τρόπο
  \item Έχουμε δεδομένα για το πρόβλημα
\end{itemize}
Πολλές φορές μία απλή επιθεώρηση των δεδομένων δεν μπορεί να μας δώσει σαφείς απαντήσεις για το πρόβλημά μας, ούτε μπορούμε να βρούμε μία συνάρτηση που να παράγει πάντα το σωστό αποτέλεσμα, παρά το γεγονός ότι παρατηρούμε να κυριαρχεί ένα συγκεκριμένο πρότυπο στην έξοδο του συστήματος. Σε αυτό το σημείο η μηχανική μάθηση παίζει έναν κρίσιμο ρόλο, αφού μπορεί να μας παράξει ένα μοντέλο για το σύστημά μας, χωρίς παράλληλα να του έχουμε ορίσει εμείς ποιό μοντέλο είναι αυτό, ούτε ποιά θα είναι η τελική συνάρτηση. Το μοντέλο παράγεται μέσα από διάφορους αλγορίθμους και περιγράφει το σύστημα με έναν ικανοποιητικό τρόπο, με αποτέλεσμα να μας δίνεται η δυνατότητα να εξάγουμε χρήσιμα συμπεράσματα τα οποία θα είχαμε μεγαλύτερη δυσκολία να παράξουμε με άλλες μεθόδους.

Η μηχανική μάθηση χρησιμοποιείται από στατιστικολόγους, μηχανικούς, επιστήμονες υπολογιστών έως επιχειρηματίες ή πολιτικούς. Συγκεκριμένα για τον κλάδο της επιχειρηματικότητας, η μηχανική μάθηση μπορεί να αποβεί καθοριστικής σημασίας για μία εταιρία, καθώς δημιουργεί αξία, αναλύοντας δεδομένα του κλάδου στον οποίο η εταιρία εδρεύει, βελτιώνοντας την λήψη αποφάσεων και ελαχιστοποιώντας τους κινδύνους. Επίσης, επιτρέπει στην επιχείρηση να προσαρμόσει με ακρίβεια τα προϊόντα ή τις υπηρεσίες της, ώστε να ανταποκρίνονται στις ανάγκες των πελατών της και, ως εκ τούτου, είναι ζωτικής σημασίας για την ανταγωνιστική θέση της εταιρίας στην αγορά.

\section{Ορολογία}

Σε κάθε σύστημα που θα εφαρμόσουμε μεθόδους μηχανικής μάθησης έχουμε ένα σύνολο εισόδων  (\textlatin{inputs}) οι οποίες επηρεάζουν μία ή περισσότερες εξόδους (\textlatin{outputs}). Ο στόχος είναι να χρησιμοποιήσουμε τις εισόδους ώστε να προβλέψουμε τις τιμές των εξόδων. Η διαδικασία αυτή ονομάζεται επιβλεπόμενη μάθηση (\textlatin{supervised learning}). Οι είσοδοι είναι οι ανεξάρτητες μεταβλητές του συστήματος και συναντώνται ως \textlatin{predictors} ενώ οι έξοδοι είναι οι εξαρτημένες μεταβλητές ή \textlatin{responses}. Σε περίπτωση που δεν έχουμε δεδομένη έξοδο, τότε το πρόβλημα είναι μη επιβλεπόμενο και χρησιμοποιούμε μεθόδους μη επιβλεπόμενης μάθησης (\textlatin{unsupervised learning}). 

Στους αλγορίθμους για επιβλεπόμενη μάθηση περιέχονται τα δέντρα απόφασης (\textlatin{decision trees}), οι μέθοδοι \textlatin{bagging}, \textlatin{boosting} και \textlatin{random forest}, η λογιστική παλινδρόμιση, όπως επίσης τα νευρωνικά δίκτυα και οι μηχανές διανυσματικής υποστήριξης (\textlatin{Support Vector Machines}, \textlatin{SVM}). Στους αλγορίθμους για μη επιβλεπόμενη μάθηση περιέχονται οι μέθοδοι ομαδοποίησης (\textlatin{clustering}), \textlatin{blind signal separation} όπως και κρυφά Μαρκοβιανά μοντέλα (\textlatin{hidden Markov models}).

Η έξοδος διαφέρει ανάλογα με το αν το αποτέλεσμα είναι ποσοτικό (\textlatin{quantitative}) ή ποιοτικό (\textlatin{qualitative}). Λέμε πως η έξοδος παίρνει ποσοτικές τιμές, όταν οι τιμές αυτές μπορούν να είναι συνεχής σε ένα φάσμα αριθμών ή να είναι διατεταγμένες. Οι τιμές είναι ποιοτικές όταν παίρνουν μη διατεταγμένες μεταβλητές και μπορούμε να τις κατηγοριοποιήσουμε σε κλάσεις. Έτσι, τα μοντέλα πρόβλεψης χωρίζονται σε δύο κατηγορίες: παλινδρόμησης (\textlatin{regression}) όταν θέλουμε να προβλέψουμε ποσοτικές μεταβλητές και ταξινόμησης (\textlatin{classification}) όταν θέλουμε να προβλέψουμε ποιοτικές.

Οι ποιοτικές μεταβλητές μπορούν να αναπαρασταθούν από κωδικούς. Για παράδειγμα αν έχουμε μόνο δύο κλάσεις (ή κατηγορίες) όπως ''επιτυχία'' ή ''αποτυχία'' μπορούμε να τις αναπαραστήσουμε με δυαδικό \textlatin{bit} 0 ή 1. Οι κωδικοί αυτοί ονομάζονται και ''στόχοι'' (\textlatin{targets}). Όταν έχουμε περισσότερες από δύο κατηγορίες πολλοί εναλλακτικοί τρόποι είναι διαθέσιμοι. Ο πιο διαδεδομένος τρόπος είναι μέσω ψευδομεταβλητής (\textlatin{dummy variable}). Μέσω αυτού μία ποιοτική μεταβλητή $Κ$-κλάσης μπορεί να αναπαρασταθεί από έναν πίνακα με $Κ$-\textlatin{bits} όπου μόνο ένα είναι ''ανοιχτό'' κάθε στιγμή \citepri{Elem}.

Η είσοδος θα αναπαρίσταται από την μεταβλητή Χ. Αν το Χ είναι διάνυσμα, τότε μπορούμε να έχουμε πρόσβαση στα στοιχεία του Χ$_{\textlatin{j}}$. Η κάθε μεταβλητή $x_j$ θα έχει \tl{p}-χαρακτηριστικά (\tl{features}). Επομένως μπορούμε να αναπαραστήσουμε την είσοδό μας ως έναν πίνακα $N\times p$. Η απόκριση θα συμβολίζεται με $\textlatin{Y}$. Οι τιμές που παρατηρήθηκαν θα συμβολίζονται με μικρό γράμμα ως $x_i$. 

Για παράδειγμα, έστω ότι έχουμε το εξής πρόβλημα \tl{classification}: Έχουμε κάποια δεδομένα επιβατών του τιτανικού, όπως όνομα, επώνυμο, ημερομηνία γέννησης, φύλο, \tl{passenger class}, και άλλες πληροφορίες, και έχουμε και ως δεδομένο αν επέζησαν ή όχι. Τότε, η είσοδός μας θα ήταν τα $N$-δεδομένα επιβατών, όπου κάθε επιβάτης θα είχε $p$-χαρακτηριστικά, σαν αυτά που αναφέρθηκαν πιο πριν. Η έξοδος θα είχε $N$ δεδομένα με δύο κλάσεις: επέζησε (0) ή πέθανε (1). 

Έστω τώρα ότι μας έρχονται νέα δεδομένα επιβατών, για τα οποία δεν γνωρίζουμε αν ο επιβάτης επέζησε ή όχι. Τότε μπορούμε μέσω μεθόδων μηχανικής μάθησης να προβλέψουμε σε ποιά κλάση θα ανήκει το νέο δεδομένο που μας ήρθε (1 ή 0) με μία καλή προσέγγιση. Επίσης, μπορούμε να βρούμε ποιά χαρακτηριστικά είναι πιο σημαντικά στο να καθορίσουν αν ο επιβάτης επέζησε ή όχι, αφού κάποια χαρακτηριστικά θα παίζουν ένα σημαντικότερο ρόλο σε σχέση με κάποια άλλα (για παράδειγμα το φύλο ή το \tl{passenger class} μπορεί να είναι πιο σημαντικά από το όνομα του επιβάτη στον καθορισμό της τελικής εξόδου). Το παράδειγμα με τον τιτανικό είναι ένα από τα βασικά προβλήματα που μπορεί να λύσει κάποιος που ξεκινάει με το \tl{machine learning} ώστε να εξασκηθεί (\citealpsec{kaggle}).
 
Μπορούμε τώρα να ορίσουμε με έναν πολύ γενικό τρόπο την μηχανική μάθηση: Έχοντας δεδομένα για ένα διάνυσμα εισόδου Χ, κάνε μία καλή πρόβλεψη για την έξοδο $\textlatin{Y}$, μέσω κάποιων κανόνων πρόβλεψης. Για την κατασκευή των κανόνων είναι απαραίτητα κάποια δεδομένα ($\textlatin{x}_{\textlatin{i}}$,$\textlatin{y}_{\textlatin{i}}$), τα οποία ονομάζονται δεδομένα εκμάθησης (\textlatin{trainining data}). Η ακρίβεια του μοντέλου θα είναι: \begin{equation} \textlatin{Accuracy} = \frac{\textlatin{Number of Correct Classifications}}{\textlatin{Total Number of Test Cases}} 
\end{equation}
\section{Διαδικασία για επιβλεπόμενη μάθηση}

Στην παρούσα διπλωματική θα ασχοληθούμε με μεθόδους επιβλεπόμενης μάθησης. Τα βήματα που ακολουθούμε είναι τα παρακάτω (\citealpsec{mathworks}):
\begin{enumerate}
  \item \textbf{Προετοιμασία Δεδομένων}\hfill \\
  Σε έναν πίνακα δεδομένων Χ, κάθε γραμμή του πίνακα θα αντιστοιχεί σε μία παρατήρηση ενώ κάθε στήλη του πίνακα αντιστοιχεί σε έναν \textlatin{predictor}. Σημεία χωρίς τιμές (\textlatin{missing values}) αναπαρίστανται και αυτά διότι ύστερα θα αντιμετωπιστούν με ειδικό τρόπο. Σε αυτό το στάδιο προετοιμάζεται το σετ εκπαίδευσης από το οποίο θα γίνει εξαγωγή της ζητούμενης συνάρτησης.   
  \item \textbf{Επιλογή Αλγορίθμου} \hfill \\
  Η επιλογή μπορεί να γίνει ανάλογα με τα ιδιαίτερα χαρακτηριστικά του κάθε αλγορίθμου και τον σκοπό που θέλουμε να πετύχουμε. Κάποια βασικά χαρακτηριστικά είναι:
  \begin{itemize}
  \item Ακρίβεια προβλέψεων
  \item Ταχύτητα εκτέλεσης αλγορίθμου
  \item Χρήση της μνήμης
  \item Ευκολία ερμηνείας αλγορίθμου
\end{itemize}
Στον πίνακα 1.1 παρουσιάζονται χαρακτηριστικά δημοφιλών αλγορίθμων επιβλεπόμενης μάθησης. 
\begin{table}[h!]
\centering
 \begin{tabular}{||c c c c||} 
 \hline
 Αλγόριθμος & Ακρίβεια & Ταχύτητα & Χρήση Μνήμης \\ 
 \hline\hline
 \textlatin{Trees} & Εξαρτάται & Γρήγορη & Χαμηλή \\ 
 \hline
 \textlatin{SVM} & Υψηλή & Εξαρτάται & Εξαρτάται \\
 \hline
 \textlatin{Naive Bayes} & Χαμηλή & Εξαρτάται & Εξαρτάται \\
 \hline
 \textlatin{Nearest Neighbor} & Εξαρτάται & Γρήγορη & Χαμηλή \\ 
 \hline
\end{tabular}
\caption{Σύγκριση χαρακτηριστικών αλγορίθμων επιβλεπόμενης μάθησης}
\label{table:1}
\end{table}
  \item \textbf{Ταίριασμα με μοντέλο} \hfill \\
  Ανάλογα με τον αλγόριθμο που επιλέγουμε, έχουμε και αντίστοιχη συνάρτηση ταιριάσματος.
  \item \textbf{Επιλογή μεθόδου επικύρωσης} \hfill \\
  Οι τρεις κύριες μέθοδοι που εξετάζουν την ακρίβεια του τελικού μοντέλου είναι: \\ \\
 \textbf{\textlatin{Resubstitution error}}\hfill \\
    Το ποσοστό σφάλματος (\textlatin{resubstitution error}) είναι μία εκτίμηση του σφάλματος βασιζόμενη στις διαφορές μεταξύ προβλεφθέντων και πραγματικών τιμών σε ένα μοντέλο μάθησης. Η απόλυτη τιμή κάθε σφάλματος προσμετράται και τελικά η διάμεσος των τιμών αυτών μας δίνει το απόλυτο υπολειμματικό σφάλμα (\textlatin{absolute residual error}) (\citealpsec{residual}).
    
    Τα δεδομένα εκπαίδευσης χρησιμοποιούνται τα ίδια για εκμάθηση οπότε οποιαδήποτε εκτίμηση της απόδοσης θα μετριέται αισιόδοξα. Ως αποτέλεσμα, το σφάλμα αυτό μπορεί να χρησιμοποιηθεί ως άνω όριο σφάλματος σε δοκιμαστικά δεδομένα. Επίσης αν το σφάλμα αυτό είναι γενικά μικρό, έχουμε μία ένδειξη πως το σύστημά μας έχει καλή απόδοση αλλά δεν μπορεί να λειτουργήσει πιο γενικευμένα, ενώ αν το σφάλμα είναι μεγαλύτερο, το σύστημα μπορεί να παρουσιάζει μεγαλύτερη διακύμανση ως προς την λειτουργία του. \\ \\
\textbf{\textlatin{Cross Validation error}}\hfill \\
  Όπως ειπώθηκε και πριν, το πρόβλημα με το ποσοστό σφάλματος είναι πως δεν μπορεί να δώσει καλές ενδείξεις για την επίδοση ενός συστήματος μάθησης όταν του ζητείται να κάνει προβλέψεις πάνω σε δεδομένα που δεν έχει ήδη δει. Ένας τρόπος να αντιμετωπίσουμε το πρόβλημα αυτό είναι να μην χρησιμοποιήσουμε ολόκληρο το σύνολο δεδομένων στη διαδικασία μάθησης. Αυτό μπορεί να πραγματοποιηθεί αφαιρώντας δεδομένα πριν την έναρξη της διαδικασίας και παίρνοντας τα δεδομένα αυτά ως εισόδους για να τεστάρουμε την απόδοση του συστήματος, συγκρίνοντας την έξοδο του μοντέλου με την πραγματική (\citealpsec{crossval}). Με αυτό τον τρόπο έχουμε ένα ''\textlatin{test model}'' κατά την φάση εκπαίδευσης του συστήματος το οποίο μας δίνει μία καλή ιδέα για το πώς το σύστημα θα συμπεριφερθεί όταν θα έρθουν δεδομένα από ένα άλλο ανεξάρτητο σύνολο \citepri{ron}.  
\newpage
Η μέθοδος \textlatin{holdout} είναι η απλούστερη μέθοδος για \textlatin{cross validation}. Τα δεδομένα χωρίζονται σε δύο σύνολα, το σύνολο εκπαίδευσης (\textlatin{training set}) και το σύνολο ελέγχου (\textlatin{testing set}). Η συνάρτηση παράγεται χρησιμοποιώντας μόνο το σύνολο εκπαίδευσης και ύστερα χρησιμοποιείται για να προβλέψει τις τιμές εξόδου του συνόλου ελέγχου, χωρίς όμως να τις γνωρίζει. Για την αξιολόγηση του μοντέλου χρησιμοποιούμε το απόλυτο υπολειμματικό σφάλμα. Η μέθοδος \textlatin{holdout} παράγει συνήθως καλύτερα αποτελέσματα χωρίς να αυξάνει τον χρόνο εκτέλεσης αλλά από την άλλη μεριά η συνάρτηση εξόδου εξαρτάται σε μεγάλο βαθμό από ποιά σημεία θα πάρουμε στο σύνολο εκπαίδευσης και ποιά στο σύνολο ελέγχου, οπότε μπορούμε να έχουμε μεγάλες αποκλίσεις στην συμπεριφορά της συνάρτησης σε διαφορετικές εκτελέσεις του αλγορίθμου \citepri{mar_cross}.

Μία βελτίωση της μεθόδου \tl{holdout} είναι το \tl{K-fold cross validation} στο οποίο το σύνολο δεδομένων μας διαιρείται σε $\tl{k}$ υποσύνολα στα οποία εφαρμόζουμε την μέθοδο \tl{holdout} $\tl{k}$ φορές. Κάθε φορά, ένα από τα $\tl{k}$ υποσύνολα χρησιμοποιείται σαν σύνολο ελέγχου ενώ τα υπόλοιπα $\tl{k}$-1 υποσύνολα ως σύνολο μάθησης. Ύστερα υπολογίζεται το μέσο σφάλμα ανάμεσα στις $\tl{k}$ δοκιμές. Με την παραπάνω διαδικασία δεν έχει τόση σημασία ο τρόπος με τον οποίο χωρίζουμε το σύνολο δεδομένων μας, αφού κάθε δεδομένο θα χρησιμοποιηθεί ως δεδομένο μάθησης $\tl{k}$-1 φορές και ως ελέγχου ακριβώς μία φορά. Ως αποτέλεσμα, η απόκλιση μειώνει όσο το $\tl{k}$ αυξάνει. Το πρόβλημα με αυτή την μέθοδο είναι πως ο αλγόριθμος πρέπει να τρέξει $\tl{k}$ φορές οπότε θα πρέπει να κάνει $\tl{k}$-υπολογισμούς για να παράξει αποτέλεσμα.

Στην περίπτωση που πάρουμε τον αλγόριθμο \tl{K-fold cross validation} και τον εφαρμόσουμε Ν φορές, όσα δηλαδή είναι τα δεδομένα μας, τότε θα έχουμε τον αλγόριθμο \tl{Leave-one-out cross validation (LOO)}. Τα αποτελέσματα που παράγει η διαδικασία αυτή είναι πολύ ικανοποιητικά, αλλά υπολογιστικά ακριβά. Έχουν αναπτυχθεί τεχνικές με βάρη που μπορούν να κάνουν τους αλγορίθμους αυτούς προσιτούς από υπολογιστική άποψη \citepri{atkeson1999locally}. 

Με το \tl{cross validation} μπορούμε να μειώσουμε προβλήματα που ίσως προκύψουν στην έξοδο του συστήματος. Ένα παράδειγμα είναι το \tl{overfitting}, το οποίο συμβαίνει όταν το μοντέλο μας περιγράφει κάποιον τυχαίο θόρυβο ή σφάλμα αντί να παράγει την επιθυμητή έξοδο. Αυτό μπορεί να συμβεί όταν το μέγεθος του συνόλου εκπαίδευσης είναι πολύ μικρό ή όταν ο αριθμός των παραμέτρων του μοντέλου είναι πολύ μεγάλος. Η διαδικασία μάθησης βελτιστοποιεί τις παραμέτρους του μοντέλου ώστε να το κάνει να ταιριάζει στα δεδομένα του συνόλου μάθησης όσο καλύτερα γίνεται \citepri{tetko1995neural}.
   
\begin{figure}[!ht] \center\leavevmode
%\epsfxsize=12cm \epsfysize=14cm
\epsfbox{fig/cross_validation.png} \caption{\textlatin{Cross Validation} και \tl{Residual error}}\label{figure:1}
\end{figure}
Στο Σχήμα \ref{figure:1} έχουμε ένα παράδειγμα στο οποίο βλέπουμε την ισχύ του \tl{cross validation} έναντι του \tl{residual error}. Στα δύο πάνω γραφήματα τα δεδομένα έχουν θόρυβο και το \tl{cross validation} προτείνει μία συνάρτηση που έχει υποστεί εξομάλυνση ενώ στα κάτω γραφήματα ο θόρυβος δεν υπάρχει και το \tl{cross validation} θα δημιουργήσει μία συνάρτηση με μικρή εξομάλυνση.\\ \\
\textbf{\textlatin{Out of bag error}} \hfill \\
Η τεχνική αυτή χρησιμοποιείται με μεθόδους \tl{bagging} ή αλλιώς \tl{bootstrap aggregation} σε δέντρα όπως \tl{random forests} και θα παρουσιαστεί αναλυτικά σε επόμενο κεφάλαιο. Η λογική της μεθόδου είναι πως μπορούμε να υπολογίσουμε το σφάλμα κατά την εκτέλεση της μεθόδου και όχι ξεχωριστά. Κάθε δέντρο δημιουργείται χρησιμοποιώντας ένα διαφορετικό δείγμα από τα δεδομένα, και περίπου το $\frac{1}{3}$ από αυτά δεν χρησιμοποιείται για την κατασκευή του $\tl{k}$ δέντρου. Τα δεδομένα που μένουν εκτός χρησιμοποιούνται για να πάρουμε ένα σύνολο δοκιμών κατάταξης (\tl{classification test set}). Έστω στο τέλος της εκτέλεσης ότι έχουμε \tl{j} την κλάση που πήρε τις περισσότερες ψήφους κάθε φορά που η περίπτωση \tl{n} ήταν εκτός δείγματος. Η μέση τιμή του ποσοστού των φορών που η τάξη \tl{j} δεν είναι ίση με την πραγματική τάξη \tl{n} σε όλες τις δυνατές περιπτώσεις είναι η εκτίμηση σφάλματος \tl{OOB}. Η τιμή αυτή έχει αποδειχτεί αμερόληπτη σε πολλές δοκιμές \citepri{berk_forests}.    

  \item \textbf{Εξέταση και ενημέρωση του μοντέλου} \hfill \\
Επόμενο βήμα είναι η βελτίωση του μοντέλου ώστε να πετύχουμε μεγαλύτερη ακρίβεια στα αποτελέσματά μας ή καλύτερη ταχύτητα εκτέλεσης ή χρησιμοποίηση λιγότερης μνήμης. Ένας τρόπος να το πετύχουμε αυτό είναι να αλλάξουμε τις παραμέτρους προσαρμογής ώστε να πάρουμε ένα πιο ακριβές μοντέλο. Για παράδειγμα μπορούμε να πάρουμε άνισα κόστη ταξινόμησης ή να αλλάξουμε το βάθος του δέντρου με το οποίο θα παίρνουμε τις μετρήσεις ή τον τρόπο κλαδέματος του δέντρου (\tl{prunning}) ή τον τρόπο με τον οποίο θα διαχωρίζουμε το δείγμα μας.
  \item \textbf{Χρησιμοποίηση του μοντέλου για προβλέψεις} \hfill \\
Σε αυτό το σημείο μπορούμε να χρησιμοποιήσουμε το μοντέλο που δημιουργήσαμε πάνω σε δείγματα χωρίς τιμές εξόδου και να παράγουμε προβλέψεις και αποτελέσματα που είναι ακριβή και με μικρό σφάλμα. Επιπλέον, είμαστε σε θέση να δοκιμάσουμε διαφορετικούς αλγορίθμους πάνω στο ίδιο δείγμα, να παρατηρήσουμε την έξοδό ώστε να έχουμε καλύτερη συνολική εικόνα και να παράγουμε πιο ακριβή συμπεράσματα.
\end{enumerate}

\newpage
\thispagestyle{empty}
