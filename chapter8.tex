\chapter{Ανάλυση Χρονοσειράς}

\section{Εισαγωγή}

Στην προηγούμενη ανάλυση είδαμε πώς συμπεριφέρονται οι αλγόριθμοι πάνω σε ολόκληρη την χρονοσειρά επιλέγοντας τυχαία δείγματα δεδομένων για \tl{training} και \tl{validation sets} και αξιολογήσαμε τους αλγορίθμους και την προγνωστική τους ικανότητα. Σε αυτό το κεφάλαιο θα ασχοληθούμε με \tl{predictions} πάνω στον χρόνο χωρίς να γνωρίζουμε ολόκληρο το σύνολο των δεδομένων. Η διαδικασία αυτή είναι αρκετά δυσκολότερη διότι μπορεί στο \tl{test set} να περιλαμβάνονται ακραίες τιμές λόγω οικονομικοπολιτικής κατάστασης της περιόδου που εξετάζεται η οποία να διαφέρει αρκετά σε σχέση με το \tl{training set}, οπότε και ο καθορισμός της εξόδου να μην είναι τόσο εύκολος. Επίσης, εφόσον δεν γνωρίζουμε τί \tl{trend} μπορεί να έχουν τα τελικά δεδομένα, είναι κρίσιμης σημασίας και ο καθροισμός του \tl{training set}, ώστε μέσω αυτού να παράγουμε τα βέλτιστα αποτελέσματα. Τέλος, επειδή έχουμε χρονοσειρά ίσως χρειαστεί να λάβουμε υπ' όψη τις προηγούμενες τιμές των μεταβλητών ώστε να ελαχιστοποιήσουμε τα σφάλματα εξόδου και να βελτιώσουμε την προγνωστική ικανότητα του μοντέλου μας.

\section{\tl{Residuals} και \tl{lagged values}}

Στο παράδειγμα που περιγράφεται έχουμε δύο τυχαίες χρονοσειρές που έχουν εξάρτηση από την προηγούμενη τιμή τους και για τις οποίες κάνουμε ένα απλό \tl{linear regression} και δημιουργούμε μία συνάρτηση της μορφής $y = \alpha x + \beta$. Ύστερα μέσω της συνάρτησης παράγουμε τις αντίστοιχες προβλεπόμενες τιμές. Τα \tl{residuals} είναι οι διαφορές που προκύπτουν από τις πραγματικές και τις προβλεπόμενες τιμές. Η διαφορά των \tl{residuals} και των σφαλμάτων είναι στις πραγματικές τιμές που λαμβάνουμε: στην πρώτη περίπτωση αφαιρούμε την εκτιμηθείσα τιμή από την γνωστή πραγματική ενώ στην δεύτερη περίπτωση από την άγνωστη πραγματική. \\

\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/residuals.png}}%
  \caption{\tl{Residuals Example}}
  \label{figure:50}
\end{figure}

\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/smp.png}}%
  \caption{Χρονοσειρά \tl{SMP}}
  \label{figure:51}
\end{figure}

Το σημαντικό γεγονός με τα \tl{residuals} είναι πως θέλουμε στο σύστημα που δημιουργούμε τα \tl{residuals} να τείνουν στο μηδέν. Μάλιστα στην ιδανική περίπτωση ο μέσος όρος αυτών είναι στο μηδέν. Στο παράδειγμα έχουμε τις παρακάτω συναρτήσεις:

\begin{equation}
X(t) = X(t-1) + \varepsilon (t), X(0)=0, \varepsilon\sim N(0,1)
\end{equation}
\begin{equation}
Y(t) = 0,2*Y(t-1) + z (t), Y(0)=0, z\sim N(0,1)
\end{equation}

Στο σχήμα \ref{figure:50} φαίνονται τα \tl{residuals} του παραδείγματος. Παρατηρούμε πως οι τιμές των σφαλμάτων κυμαίνονται κοντά στο μηδέν. Μάλιστα ο μέσος όρος των \tl{residuals} στο συγκεκριμένο παράδειγμα είναι 0.0028.

\begin{minted}[linenos]{python}
import numpy as np
import matplotlib.pyplot as plt
n=100
e = np.random.rand(n) 
x =np.zeros(n)
for i in range (1,n):
    x[i] = x[i-1] + e[i-1]
    
z = np.random.rand(n)
y =np.zeros(n)
for i in range (1,n):
    y[i] = 0.2*y[i-1] + z[i-1]
    
reg = np.polyfit(x, y, 1)
y_pred = reg[0]*x + reg[1]
res = y-y_pred

m = 0
for i in range(1,n):
    m = m + res[i-1]
ave_res = m/n

plt.figure()
plt.plot(res)
plt.xlabel('data')
plt.ylabel('y-y_pred')
plt.title('Residuals Example')
plt.show()
\end{minted} 
\newpage
Με την προσθήκη \tl{lagged} μεταβλητών, δηλαδή μεταβλητών που περιέχουν τις προηγούμενες χρονικές τιμές $t-1, t-2, \dots$, μπορούμε να κάνουμε το σύστημά μας πιο σταθερό και με \tl{residuals} πιο κοντά στο μηδέν. Με αυτό τον τρόπο θα έχουμε και καλύτερη προβλεπτική ικανότητα. Αυτό δεν μπορεί να γίνει εφικτό όταν λαμβάνουμε τυχαίες μεταβλητές σε όλο το δείγμα για \tl{training} και \tl{validation sets}, αφού τότε δημιουργούμε διαφορετικές χρονοσειρές. Ανάλογα με το αν το δείγμα μας είναι ομοιογενές ή όχι, παράγουμε και τα αντίστοιχα αποτελέσματα. Όσο πιο ομοιογενές είναι το δείγμα, τόσο περισσότερο βοηθά η χρήση \tl{lagged} μεταβλητών. 

Στο σχήμα \ref{figure:51} παρουσιάζεται η χρονοσειρά του \tl{SMP} από 1/1/09 έως 30/11/13. Το γράφημα δημιουργήθηκε ώστε να κάτανοήσουμε σε ποιά σημεία τα δεδομένα μας είναι ομοιογενή ώστε να δούμε πού πρέπει να φτιάξουμε \tl{training} και \tl{validation sets}. Παρατηρούμε πως από τα μέσα του 2009 έως τις αρχές του 2011 η χρονοσειρά είναι ομαλή οπότε μπορούμε να υποθέσουμε πως ένας καλός αλγόριθμος μηχανικής μάθησης θα μπορούσε να παράγει ικανοποιητικές προβλέψεις. Από τα μέσα του 2011 και έπειτα όμως η χρονοσειρά δεν είναι ομαλή παρουσιάζοντας αυξομειώσεις λόγω της πολιτικής και οικονομικής κατάστασης που επικράτησε στην χώρα μας. Ειδικά για την περίοδο 2013 έχουμε πολύ μεγάλες διακυμάνσεις στο \tl{SMP} και η πρόβλεψη θα είναι σαφώς δυσκολότερη. 


\section{Επιλογή \tl{lagged} μεταβλητών}

Αρχικά εφαρμόσαμε τον αλγόριθμο \tl{Random Forests} στα δεδομένα μας για διαφορετικά \tl{lagged values}. Συγκεκριμένα ο αλγόριθμος εφαρμόστηκε για δεδομένα χωρίς \tl{lagged} μεταβλητές έως δεδομένα με μεταβλητές χρόνου $t-3$. Για την δημιουργία των \tl{lagged} μεταβλητών χρησιμοποιήσαμε την εντολή \tl{shift} από την βιβλιοθήκη \tl{pandas} ώστε να μετακινήσουμε τα δεδομένα ενός \tl{dataframe} τις θέσεις που θέλουμε.

Ο αλγόριθμος εφαρμόστηκε για διαφορετικά \tl{train} και \tl{test sets} μέσα στην χρονοσειρά, ξεκινώντας από \tl{training sets} των 100 μεταβλητών έως \tl{training sets} των 1600 μεταβλητών. Τα αποτελέσματα φαίνονται στα γραφήματα \ref{figure:52} έως \ref{figure:55}. Παρατηρούμε πως με την προσθήκη \tl{lagged} μεταβλητών το σύστημα έκανε καλύτερες προβλέψεις σε σχέση με το αντίστοιχο χωρίς τις \tl{lagged} μεταβλητές. Το γεγονός αυτό έχει να κάνει με την ανομοιογένεια της χρονοσειράς, η οποία επηρεάζει αρνητικά την ακρίβεια του μοντέλου και κάνει τις προβλέψεις δύσκολες. Η εισαγωγή μεταβλητών που περιέχουν πληροφορία της προηγούμενης χρονικής στιγμής βοηθά σε σημαντικό βαθμό το μοντέλο και την παραγωγή προβλέψεων. Η επιπλέον προσθήκη παλαιότερων μεταβλητών επηρεάζει λιγότερο θετικά, μάλιστα μετά από ένα σημείο επηρεάζει αρνητικά στην ακρίβεια του μοντέλου. Σύμφωνα με τα γραφήματα η βέλτιστη ακρίβεια λαμβάνεται με προσθήκη \tl{lagged} μεταβλητών έως $t-2$. 
\newpage
\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/variance_data_size.png}}%
  \caption{\tl{Variance for different lagged values}}
  \label{figure:52}
\end{figure}
Το πρώτο σημαντικό σημείο που παρατηρούμε είναι πως η ακρίβεια είναι αρκετά χαμηλότερη από αυτή που πετύχαμε στο προηγούμενο κεφάλαιο όπου χωρίσαμε την χρονοσειρά σε τυχαία \tl{training} και \tl{validation sets}, ακόμα και με την προσθήκη \tl{lagged} μεταβλητών. Αυτό είναι αποτέλεσμα της ανομοιογένειας της χρονοσειράς που μελετάμε όπως και της ομοιογένειας των χρονοσειρών που δημιουργήσαμε στο προηγούμενο κεφάλαιο. Κατά την δημιουργία των προηγούμενων σετ μάθησης και επικύρωσης σημαντικό ρόλο έπαιζε η ελαχιστοποίηση των σφαλμάτων και η βελτιστοποίηση της επίδοσης των αλγορίθμων, οπότε και τα γραφήματα που δημιουργήθηκαν είχαν την αντίστοιχη δομή. Με αυτό τον τρόπο είδαμε ποιά χαρακτηριστικά είναι τα πιο σημαντικά μέσα στην χρονοσειρά όπως και την δύναμη του κάθε αλγορίθμου και την προβλεπτική του ικανότητα. Τώρα θέλουμε να βρούμε τον βέλτιστο τρόπο δημιουργίας του μοντέλου όπως και σε ποιά σημεία οι αλγόριθμοι παρουσιάζουν την καλύτερη συμπεριφορά σε σχέση με πραγματικές προβλέψεις.   

Στο σχήμα \ref{figure:53} έχουμε το \tl{explained Variance} (ακρίβεια μοντέλου) για τα διαφορετικά \tl{lagged values} που χρησιμοποιήθηκαν. Η καλύτερη ακρίβεια επιτυγχάνεται με \tl{training set} 1000-1100 τιμών με \tl{lagged values}, δηλαδή 60\% του συνόλου και 40\% \tl{validation set}. Η ακρίβεια είναι κοντά στο 60\%, μία πολύ καλή συμπεριφορά για τα ανομοιογενή δεδομένα μας. Επίσης παρατηρούμε πως για μετάλο \tl{training set}, μικρό \tl{test set} έχουμε χαμηλή ακρίβεια, και μάλιστα καλύτερη ακρίβεια με το μοντέλο χωρίς τα \tl{lagged values}. Αυτό οφείλεται στο γεγονός ότι τα δεδομένα του \tl{SMP} των τελευταίων 3 μηνών παρουσιάζουν πολύ μεγάλες αποκλίσεις μεταξύ τους.

\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/cross_validation_data_size.png}}%
  \caption{\tl{Cross Validation for different lagged values}}
  \label{figure:53}
\end{figure}

\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/mae_data_size.png}}%
  \caption{\tl{MAE for different lagged values}}
  \label{figure:54}
\end{figure}

\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/residuals_data_size.png}}%
  \caption{\tl{Residuals for different lagged values}}
  \label{figure:55}
\end{figure}

Στα σχήματα \ref{figure:53} και \ref{figure:54} βλέπουμε το \tl{cross validation} και \tl{MAE}. Το \tl{MAE} όπως και το \tl{MSE} είναι ελάχιστα για \tl{lagged values} $t-2$ σύμφωνα και με αυτά που είπαμε πριν. Το \tl{cross validation} είναι καλύτερο με \tl{lagged} μεταβλητές, λόγω της βελτίωσης του μοντέλου και των \tl{residuals}. Όσον αφορά τα \tl{residuals}, έχουμε καλύτερες τιμές (κοντά στο μηδέν) για \tl{t-1} και \tl{t-2}.

Όσον αφορά τα \tl{importances} των μεταβλητών, ανάλογα με το μέγεθος του δείγματος είχαμε διαφορετικές σημαντικότητες, με το \tl{ngas} να έχει μικρότερη σημαντικότητα σε μικρά δείγματα και να αυξάνει σημαντικότητα όσο είχαμε περισσότερα δεδομένα στο \tl{training set}. Για τις προβλέψεις που είχαν καλό \tl{accuracy} το \tl{ngas} είχε σημαντικότητα στο 0.34 χωρίς \tl{lagged values} και στο 0.11 με \tl{lagged} μεταβλητές ενώ τότε η πιο σημαντική μεταβλητή ήταν η τιμή $SMP(t-1)$ με \tl{importance} στο 0.45. 

Ύστερα επιχειρήσαμε να προβλέψουμε ένα συγκεκριμένο \tl{test set} το οποίο περιείχε τις τελευταίες 100 τιμές της χρονοσειράς, και τα αποτελέσματα ήταν αντίστοιχα με πριν. Οι μεταβλητές με \tl{lagged values} για $t-2$ ήταν ελάχιστα πιο ακριβείς από \tl{t-1} και μας έδωσαν τα καλύτερα αποτελέσματα. Σημαντικό το γεγονός ότι ο αλγόριθμος \tl{MARS} πετυχαίνει και αυτός πολύ καλά αποτελέσματα.

Στα σχήματα \ref{figure:56} έως \ref{figure:58} φαίνονται οι προβλέψεις για \tl{Random Forests} χωρίς \tl{lagged} μεταβλητές όπως και προβλέψεις με \tl{lagged t-2 values} με χρήση των αλγορίθμων \tl{Random Forests} και \tl{MARS}. Η διαφορά μεταξύ των σχημάτων για \tl{t-1} και \tl{t-2 lagged values} είναι πολύ μικρή με πιο ομαλοποιημένα αποτελέσματα για \tl{t-2}. Η υπόλοιπη ανάλυση θα γίνει με \tl{lag t-2} στους αλγορίθμους \tl{Random Forest}, \tl{MARS} και \tl{CART}. 

\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/no_lagg.png}}%
  \caption{\tl{Random Forest - no lag}}
  \label{figure:56}
\end{figure}

\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/t-2.png}}%
  \caption{\tl{Random Forest - lag} έως \tl{t-2}}
  \label{figure:57}
\end{figure}

\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/mars_t-2.png}}%
  \caption{\tl{MARS - lag} έως \tl{t-2}}
  \label{figure:58}
\end{figure}

\section{Ανάλυση Χρονοσειράς}

Στην επεξεργασία της χρονοσειράς χρησιμοποιήθηκαν και οι τρεις αλγόριθμοι με \tl{lagged values} έως $t-2$. Χρησιμοποιήθηκαν 3 διαφορετικοί τρόποι επεξεργασίας δεδομένων, τους οποίους αναλύουμε παρακάτω.

\subsection{Διαφορετικά \tl{train} και \tl{validation sets} σε όλη την χρονοσειρά}

Αρχικά εφαρμόσαμε τους τρεις αλγορίθμους σε \tl{train} και \tl{test sets} που κάλυπταν όλη την χρονοσειρά. Το πιο μικρό \tl{train set} ξεκινούσε από την αρχή έως τα 100 πρώτα δεδομένα και το υπόλοιπο ήταν \tl{test set}, ενώ αυξάναμε κάθε φορά κατά 100 επιπλέον δεδομένα το \tl{train set} και μειώναμε αντίστοιχα το \tl{test set} ώσπου στο τέλος είχαμε 100 δεδομένα για \tl{test}. Στο σχήμα \ref{figure:59} φαίνεται η διαδικασία που ακολουθήθηκε. Σε κάθε βήμα αποθηκεύαμε σε πίνακες τα δεδομένα για \tl{Mean Accuracy, Variance, MAE, MSE} όπως και τις σημαντικότητες των μεταβλητών και ταυτόχρονα δημιουργούσαμε γραφικές παραστάσεις των προβλέψεων σε σχέση με τα πραγματικά μεγέθη.
\newpage

\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/1.png}}%
  \caption{Ανάλυση δεδομένων 1}
  \label{figure:59}
\end{figure}

\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/variance1.png}}%
  \caption{\tl{Variance} - Ανάλυση 1η}
  \label{figure:65}
\end{figure}

\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/mae1.png}}%
  \caption{MAE - Ανάλυση 1η}
  \label{figure:66}
\end{figure}

Ο αλγόριθμος \tl{MARS} παρουσίασε πολύ καλά αποτελέσματα, μάλιστα σε κάποια σημεία έφτασε ακρίβεια 70\%. Ταυτόχρονα όμως για διαφορετικά δεδομένα είχε πολύ κακή επίδοση. Αντίθετα ο αλγόριθμος \tl{Random Forests} ήταν πιο αξιόπιστος σε όλη την διάρκεια αλλά με μικρότερη επίδοση σε σχέση με τον \tl{MARS} σε κάποια σημεία. Οι αλγόριθμοι παρουσίασαν τα βέλτιστα αποτελέσματα για \tl{train set} μεγέθους 1000, το οποίο περιέχει μέσα όλες τις αρχικές τιμές της χρονοσειράς μαζί με κάποιες υψηλότερες τιμές. Στο σχήμα \ref{figure:51} που περιέχει το \tl{SMP}, το βέλτιστο \tl{train set} για την πρόβλεψη των υπόλοιπων τιμών έγινε από τις αρχές τους 2009 έως τέλη του 2011. Στην βέλτιστη περίπτωση ο αλγόριθμος \tl{MARS} έχει \tl{variance} στο 57\% και παράγει καλύτερα αποτελέσματα. Σε άλλα \tl{training set} όμως παρουσίασε βύθιση παράγοντας λανθασμένη έξοδο.

Όσον αφορά την σημαντικότητα των μεταβλητών, τόσο στον αλγόριθμο \tl{Random Forest} όσο και στον αλγόριθμο \tl{MARS} η πιο σημαντική μεταβλητή ήταν το \tl{SMP(t-1)} ακολουθούμενο από το \tl{ngas}. Στα \tl{Random Forest} επόμενη πιο σημαντική μεταβλητή ήταν το \tl{smp(t-2)} και έπειτα ερχόταν το \tl{load\_forecast}, \tl{ngas(t-1)}, \tl{waip} και \tl{waters}. Στον αλγόριθμο \tl{MARS} τρίτη σημαντικότερη μεταβλητή ήταν το \tl{ngas(t-1)} ακολουθούμενο από τα \tl{smp(t-2)}, \tl{load\_forecast} και \tl{waip}. Συνολικά η σημαντικότητα των μεταβλητών παρουσιάζει πολλές ομοιότητες στους δύο αλγορίθμους.

\subsection{Διαφορετικά \tl{train sets} - ίδιο \tl{test set}}

Τώρα έχουμε ένα \tl{validation set} στο διάστημα [1600:] και διαφορετικά \tl{train sets} τα οποία ανήκουν στο διάστημα [:1600-\tl{x}], $x_0 = 0$ και \tl{x} αυξάνει ανά 100. Το παραπάνω φαίνεται στο σχήμα \ref{figure:60}. 

\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/2.png}}%
  \caption{Ανάλυση δεδομένων 2}
  \label{figure:60}
\end{figure}

\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/variance2-2.png}}%
  \caption{\tl{Variance} - Ανάλυση 2η}
  \label{figure:68}
\end{figure}

\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/figure_16--1.png}}%
  \caption{\tl{Random Forest} και \tl{MARS} - \tl{Real - Predicted}}
  \label{figure:67}
\end{figure}

Τα αποτελέσματα φαίνονται στο σχήμα \ref{figure:68} και είναι παρόμοια με πριν. Έχουμε σε κάποια σημεία καλύτερες τιμές στο \tl{MARS}, αλλά σε κάποια άλλα τιμές λανθασμένες. Το \tl{Random Forest} παράγει μέτρια αποτελέσματα ενώ το \tl{MARS} παράγει τα βέλτιστα αποτελέσματα για \tl{training sets} 1500 και 1600 τιμών, δηλαδή ολόκληρου του δείγματος. Η σημαντικότητα των μεταβλητών σε αυτά τα δείγματα παραμένει ίδια με πριν και στους δύο αλγορίθμους. Επίσης παρατηρούμε πως εδώ ο αλγόριθμος \tl{CART} δεν παράγει ικανά αποτελέσματα για προβλέψεις.

Στο σχήμα \ref{figure:67} έχουμε τις διαφορές των πραγματικών από τις εκτιμηθείσες τιμές για τους αλγορίθμους \tl{Random Forest} και \tl{MARS} και για \tl{train set} 1600 τιμών. Παρατηρούμε πως ο αλγόριθμος \tl{MARS} συνολικά δίνει καλύτερα αποτελέσματα. Οι αλγόριθμοι παίρνουν τιμές με μεγάλη απόκλιση από την πραγματική στα ίδια σημεία και συνολικά παρουσιάζουν παρόμοια συμπεριφορα.


%\subsection{Διαφορετικά \tl{train} και \tl{validation sets} σε όλη την χρονοσειρά (αντίστροφο 1)}
%
%Εδώ έχουμε την ίδια διαδικασία που έγινε στην πρώτη περίπτωση με την διαφορά πως κάνουμε \tl{test} τις παλαιότερες τιμές του \tl{SMP} με βάση τις πιο πρόσφατες. Τα βήματα είναι ίδια με πριν και η διαδικασία φαίνεται στο σχήμα \ref{figure:61}.
%\newpage
%\begin{figure}
%  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/3.png}}%
%  \caption{Ανάλυση δεδομένων 3}
%  \label{figure:61}
%\end{figure}
%
%\begin{figure}
%  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/variance3-3.png}}%
%  \caption{\tl{Variance} - Ανάλυση 3η}
%  \label{figure:69}
%\end{figure}
%
%\begin{figure}
%  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/figure_16-3.png}}%
%  \caption{\tl{Random Forest} και \tl{MARS} - Ανάλυση 3η}
%  \label{figure:70}
%\end{figure}
%
%Όπως και στις προηγούμενες περιπτώσεις ο αλγόριθμος \tl{MARS} είναι πιο ασταθής αλλά σε συγκεκριμένα σημεία μπορεί να παράξει τα βέλτιστα αποτελέσματα. Ο αλγόριθμος \tl{Random Forest} παρέχει συνεχόμενα πολύ καλές προβλέψεις στην συγκεκριμένη περίπτωση φτάνοντας κοντά στο 70\%. Ο αλγόριθμος \tl{MARS} φτάνει το 77,5\% για το ίδιο τεστ, αποτέλεσμα εξαιρετικό. Στο σχήμα \ref{figure:70} έχουμε τα αποτελέσματά τους για το συγκεκριμένο \tl{iteration}. Εδώ πρέπει να τονιστεί πως η πρόβλεψη ήταν ευκολότερη σε σχέση με πριν λόγω της ομοιογένειας των αρχικών δεδομένων του \tl{SMP}. Όσον αφορά την σημαντικότητα των μεταβλητών, σε αυτή την περίπτωση έχουμε αυξημένη σημαντικότητα της μεταβλητής \tl{waters} σε σχέση με το \tl{load\_forecast}, αλλά ξανά οι πιο σημαντικές μεταβλητές είναι το \tl{SMP(t-1)} και \tl{ngas}. 
%
%\subsection{Διαφορετικά \tl{train}, ίδιο \tl{test} (αντίστροφο 2)}
%
%Επόμενο βήμα ήταν η αντίστροφη ανάλυση ενός συγκεκριμένου \tl{test set} στα αρχικά δεδομένα το οποίο άνηκε στο διάστημα [100:400]. Τα \tl{train sets} ξεκινούσαν από όλο το διάστημα της χρονοσειράς και μίκραιναν έως το διάστημα [400:500]. 
%\newpage
%\begin{figure}
%  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/4.png}}%
%  \caption{Ανάλυση δεδομένων 4}
%  \label{figure:62}
%\end{figure}
%
%\begin{figure}
%  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/var4.png}}%
%  \caption{\tl{Variance} - Ανάλυση 4η}
%  \label{figure:71}
%\end{figure}
%
%\begin{figure}
%  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/analysi4.png}}%
%  \caption{\tl{Random Forest} και \tl{MARS} - Ανάλυση 4η}
%  \label{figure:72}
%\end{figure}
%
%\begin{figure}
%  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/marsnice.png}}%
%  \caption{\tl{MARS} - Ανάλυση 4η}
%  \label{figure:73}
%\end{figure}
%
%Τα αποτελέσματα είναι παρόμοια με πριν. Ο αλγόριθμος \tl{Random Forest} δίνει σταθερά αποτελέσματα κοντά στο 60\% ενώ ο αλγόριθμος \tl{MARS} δίνει καλά αποτελέσματα μόνο σε συγκεκριμένα σημεία. Το βέλτιστο αποτέλεσμα είναι 65.9\% από τον αλγόριθμο \tl{MARS} το οποίο επιτυγχάνεται για \tl{training set} μεγέθους μόλις 300 δεδομένων. Το αποτέλεσμα αυτό είναι λογικό δεδομένης της χρονοσειράς που εξετάζουμε: το \tl{validation set} ξεκινά από αρχές του 2009 και σταματά Φεβρουάριο 2010 όπως φαίνεται στο σχήμα \ref{figure:51}. Το δείγμα με το μεγαλύτερο \tl{accuracy} ξεκίνησε αμέσως μετά και τελείωσε Ιανουάριο 2011. Τα δεδομένα των δύο περιόδων είναι ομοιογενή με παρόμοια χαρακτηριστικά επομένως η σωστή πρόβλεψή τους είναι ευκολότερη.
%
%Ενδιαφέρον παρουσιάζουν τα \tl{importances} των μεταβλητών: παρότι πιο σημαντική παραμένει η μεταβλητή \tl{SMP(t-1)} τώρα έχει σημαντικότητα στο 21.5\% σε σχέση με 45\% στις προηγούμενες περιπτώσεις. Αυτό οφείλεται στο γεγονός πως έχουμε μεγαλύτερη ομοιογένεια οπότε οι \tl{lagged} μεταβλητές δεν είναι τόσο σημαντικές. Δεύτερο έρχεται το \tl{ngas} με αυξημένη σημαντικότητα σε σχέση με πριν (λόγω μειωμένης σημαντικότητας \tl{SMP(t-1)}) και στις επόμενες θέσεις τα \tl{SMP(t-2)} και \tl{load\_forecast}. Ο αλγόριθμος \tl{MARS} κλάδεψε τις περισσότερες μεταβλητές και χρησιμοποιήσε εκτός από αυτές που προαναφέραμε τις μεταβλητές \tl{waters}, \tl{waters(t-1)}, \tl{lignite}, \tl{lignite(t-1)} και \tl{load\_forecast(t-1)} δηλαδή 9 μεταβλητές από τις 32 με πολύ καλό τελικό αποτέλεσμα. Στο σχήμα \ref{figure:72} φαίνονται οι χρονοσειρές για \tl{train set} στο διάστημα [400:700].

\subsection{Μικρά \tl{train-test sets} σε ολη την χρονοσειρά}

Για την επίδοση τμημάτων δεδομένων στην χρονοσειρά, παίρνουμε \tl{train sets} της μορφής [$x$:$x$+200] και \tl{test sets} της μορφής [$x$+200:$x$+400], όπου $x_0=0$ και $x$ αυξάνει κατά 100 σε κάθε \tl{iteration}. Στο σχήμα \ref{figure:63} βλέπουμε την διαδικασία εποπτικά. 

Τα αποτελέσματα είναι παρόμοια με πριν. Ο αλγόριθμος \tl{Random Forest} έχει μεγάλη αξιοπιστία αλλά ο \tl{MARS} μπορεί να δώσει καλύτερες προβλέψεις σε κάποιες περιπτώσεις ενώ σε κάποιες άλλες παράγει λανθασμένη έξοδο. Πιο συγκεκριμένα, ο αλγόριθμος \tl{MARS} πετυχαίνει την βέλτιστη απόδοση στο \tl{train set} [800:1000] ενώ ο \tl{Random Forest} στο [900:1100]. Πολύ καλές επιδόσεις και από τους δύο αλγορίθμους υπάρχουν και σε άλλα σημεία της χρονοσειράς. Το βασικό χαρακτηριστικό όλων των σημείων είναι η ομοιογένειά τους, πράγμα που βοηθά τους αλγορίθμους στις προβλέψεις. Σημαντικό το γεγονός πως το μέσο απόλυτο σφάλμα είναι ελάχιστο και στους τρεις αλγορίθμους στο αρχικό κομμάτι της χρονοσειράς.

Σχετικά με τις σημαντικότητες, ο αλγόριθμος \tl{Random Forest} βγάζει παρόμοια χαρακτηριστικά με πριν, με πολύ σημαντικό ρόλο να παίζει το \tl{SMP(t-1)} και το \tl{ngas} αλλά λόγω του μικρού δείγματος δεδομένων έχουμε αστάθεια στην σημαντικότητα της κάθε μεταβλητής. Στον αλγόριθμο \tl{MARS} όμως τα πράγματα είναι ακόμη πιο διαφορετικά, με το \tl{ngas} να κλαδεύεται κατά την δεύτερη φάση του αλγορίθμου και να μην παίζει ρόλο στην έξοδο. Στο σημείο [1100:1300] μάλιστα το \tl{ngas} και το \tl{SMP(t-1)} δεν χρησιμοποιήθηκαν καθόλου για τον καθορισμό της εξόδου με μεγαλύτερο ρόλο να παίζουν οι μεταβλητές \tl{load\_forecast} και \tl{waters}. Στο συγκεκριμένο σημείο είχαμε παρόμοια αποτελέσματα και για τον αλγόριθμο \tl{Random Forest} ο οποίος θεώρησε την πιο σημαντική μεταβλητή το \tl{load\_forecast} με 36.5\%, 9.7\% το \tl{ngas} και 8.9\% το \tl{SMP(t-1)}. Δύο στιγμιότυπα του αλγορίθμου \tl{MARS} φαίνονται στα σχήματα \ref{figure:76} και \ref{figure:77}.

\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/5.png}}%
  \caption{Ανάλυση δεδομένων 3}
  \label{figure:63}
\end{figure}

\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/var5.png}}%
  \caption{\tl{Variance} - Ανάλυση 3η}
  \label{figure:74}
\end{figure}

\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/mae5.png}}%
  \caption{\tl{MAE} - Ανάλυση 3η}
  \label{figure:75}
\end{figure}

\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/mars111.png}}%
  \caption{\tl{MARS} Στιγμιότυπο - Ανάλυση 3η}
  \label{figure:76}
\end{figure}

\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/realpredanalysi3.png}}%
  \caption{\tl{Random Forest} και \tl{MARS} - \tl{Real - Predicted} Ανάλυση 3}
  \label{figure:77}
\end{figure}

%\subsection{Μικρά \tl{train-test sets} (αντίστροφο 5)}
%
%Αυτή τη φορά κοιτάμε την χρονοσειρά με μικρά \tl{train} και \tl{test sets} με τον αντίστροφο τρόπο από πριν, δηλαδή τα \tl{train sets} βρίσκονται δεξιά από τα \tl{validation sets}. Στο σχήμα \ref{figure:64} βλέπουμε αναλυτικά την διαδικασία και στα σχήματα \ref{figure:78} και \ref{figure:79} βλέπουμε το \tl{Variance} και \tl{MAE} αντίστοιχα. Όπως και στις προηγούμενες περιπτώσεις, σε κάποια σημεία ο αλγόριθμος \tl{MARS} δίνει καλύτερα αποτελέσματα από το \tl{Random Forest} ενώ σε κάποια άλλα σημεία δίνει \tl{Variance} κάτω από μηδέν. Το ίδιο ισχύει και για το \tl{MAE} και \tl{MSE}, όπου στις περισσότερες περιπτώσεις ο αλγόριθμος \tl{Random Forest} έχει μικρότερο σφάλμα αλλά σε κάποια σημεία έχουμε την βέλτιστη επίδοση με τον αλγόριθμο \tl{MARS}. Οι περιοχές στις οποίες τα αποτελέσματα είναι επισφαλή είναι παρόμοιες με τις περιοχές που μελετήσαμε στην προηγούμενη περίπτωση. Σημαντικό είναι πως οι αλγόριθμοι πέτυχαν την καλύτερη επίδοση στο ίδιο \tl{training set}, το οποίο ήταν [1400:1600] με \tl{validation} [1200:1400].
%\newpage
%Όσον αφορά τις σημαντικότητες των μεταβλητών, όπως και πριν έχουμε πολύ μεγάλη διαφορά σε σχέση με τις προηγούμενες περιπτώσεις τόσο στη σημαντικότητα των μεταβλητών όσο και στην σταθερότητα του μοντέλου. Οι μεταβλητές που συμβάλουν στα δεδομένα είναι αρκετά διαφορετικές από των προηγούμενων περιπτώσεων όπως επίσης σε κάθε \tl{iteration} έχουμε διαφορετικές μεταβλητές που μετράνε στο αποτέλεσμα. Αυτό έχει να κάνει με το μικρό μέγεθος του δείγματος όπως και του \tl{test set}, πράγμα που αύξησε την ανομοιογένεια των δεδομένων. Αυτός ήταν και ο λόγος που είχαμε και μικρότερες επιδόσεις και από τους δύο αλγορίθμους. 
%
%Πιο αναλυτικά για την βέλτιστη περίπτωση, ο αλγόριθμος \tl{Random Forest} θεωρεί σημαντικότερη μεταβλητή το \tl{ngas} στο 19.3\%, δεύτερη πιο σημαντική μεταβλητή το \tl{load\_forecast} στο 17.6\% και έπειτα έρχεται το \tl{SMP(t-1)} με 12.7\%. Σημαντικό ρόλο παίζουν επίσης τα \tl{imports} και \tl{exports}. Όσον αφορά τον αλγόριθμο \tl{MARS}, στο σχήμα \ref{figure:80} έχουμε τα αποτελέσματα για την βέλτιστη επίδοσή του η οποία όπως παρατηρούμε δεν είναι υψηλή. Οι μεταβλητές \tl{ngas} και \tl{SMP(t-1)} έχουν κλαδευτεί από την τελική συνάρτηση και μετράνε μόνο οι μεταβλητές \tl{exports, exports(t-1), imports, res\_forecast, load\_forecast, lignite(t-1)} και \tl{waters}.
%
%\begin{figure}
%  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/6.png}}%
%  \caption{Ανάλυση δεδομένων 6}
%  \label{figure:64}
%\end{figure}
%
%
%\begin{figure}
%  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/var6.png}}%
%  \caption{\tl{Variance} - Ανάλυση 6η}
%  \label{figure:78}
%\end{figure}
%
%\begin{figure}
%  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/mae6.png}}%
%  \caption{\tl{MAE} - Ανάλυση 6η}
%  \label{figure:79}
%\end{figure}
%
%\begin{figure}
%  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/mars6.png}}%
%  \caption{\tl{MARS} - Ανάλυση 6η}
%  \label{figure:80}
%\end{figure}

\section{\tl{Partial Dependence Plots}}

\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/partial1.png}}%
  \caption{\tl{Partial Dependence - Target Features}}
  \label{figure:110}
\end{figure}

Τα \tl{partial dependence plots} δείχνουν την εξάρτηση μεταξύ μίας συνάρτησης στόχου και των σημαντικότερων χαρακτηριστικών που την καθορίζουν (\tl{target features}) (\citealpsec{kdkeys}).

Για την δημιουργία των διαγραμμάτων επιλέξαμε τις μεταβλητές \tl{ngas, SMP(t-1), load\_forecast} και \tl{waters} πάνω στο δείγμα της χρονοσειράς με \tl{train set} [:1600] και \tl{validation set} [1600:]. Τα \tl{partial dependence plots} των \tl{target features} φαίνονται στο σχήμα \ref{figure:110}. Ο κάθετος άξονας είναι το \tl{SMP} ομαλοποιημένο ως προς τις μεταβλητές που εξετάζουμε ενώ στον οριζόντιο άξονα έχουμε τα \tl{target features}. Εξαίρεση αποτελεί το τελευταίο σχήμα στο οποίο δημιουργούμε επιφάνειες ώστε να απεικονίσουμε την σχέση δύο μεταβλητών με την έξοδο. 

\begin{figure}
  \makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{fig/load_forecast-ngas.png}}%
  \caption{\tl{Partial Dependence of SMP on load\_forecast and ngas}}
  \label{figure:111}
\end{figure}

Αρχικά για το \tl{ngas} και το \tl{SMP} έχουμε μία σχέση που δείχνει σχεδόν σταθερή για μικρές τιμές \tl{SMP} και αυξάνει απότομα όταν η τιμή του \tl{SMP} μεγαλώνει. Αυτό έχει να κάνει με το γεγονός πως για μικρές τιμές ζήτησης και τιμής η παραγωγή φυσικού αερίου δεν επηρεάζει τόσο τις τιμές, λόγω του \tl{Variable Cost Recovery Mechanism} που περιγράφτηκε στο κεφάλαιο 5. Σε χαμηλή ζήτηση οι παραγωγοί φυσικού αερίου λειτουργούν με χαμηλή δυναμικότητα και επιδοτούνται με τη διαφορά του μεταβλητού τους κόστους, οπότε το τελικό κόστος του φυσικού αερίου δεν εισέρχεται στις τιμές του \tl{SMP} οπότε σε αυτή την περιπτώση η παραγωγή φυσικού αερίου δεν επηρεάζει τόσο την τιμή. Αντίθετα, όταν η ζήτηση αυξάνει, το φυσικό αέριο έχει έναν πολύ σημαντικό ρόλο στον καθορισμό της προσφοράς λόγω του υψηλού οριακού κόστους παραγωγής του (κεφάλαιο 5.3) οπότε και είναι σημαντικός παράγοντας καθορισμού της τιμής του \tl{SMP}.


Στο επόμενο μικρό σχήμα έχουμε την \tl{lagged value} του \tl{SMP} \tl{(SMP(t-1))} η οποία βοηθά πάρα πολύ τα μοντέλα να πετύχουν καλύτερες προβλέψεις. Αυτό συμβαίνει διότι μέσω \tl{lagged} μεταβλητών έχουμε την δυνατότητα να προσδιορίσουμε την τάση της χρονοσειράς, οπότε και να πετύχουμε καλύτερα αποτελέσματα. Παρατηρούμε πως η σχέση είναι σχεδόν γραμμική εκτός από ένα μικρό αρχικό κομμάτι, το οποίο σημαίνει πως η μεταβλητή αυτή είναι σημαντική σε ολόκληρο το μοντέλο.

Στο τρίτο σχήμα έχουμε την ζήτηση σε σχέση με το \tl{SMP}. Αρχικά υπάρχει μία σχεδόν γραμμική συμπεριφορά των δύο μεταβλητών, αλλά μετά από κάποιο σημείο η επιπλέον αύξηση της ζήτησης δεν μπορεί να επηρεάσει το \tl{SMP}. Αυτό συμβαίνει διότι το \tl{SMP} είναι φραγμένη μεταβλητή και παίρνει τιμές στο διάστημα (0,150] οπότε μετά από κάποιο σημείο η επιπλέον αύξηση της ζήτησης δεν μπορεί να προκαλέσει αλλαγή στην τιμή. Επίσης το μοντέλο μας σταθεροποιείται μετά από κάποια τιμή ζήτησης και οι μεταβλητές του επηρεάζουν με συγκεκριμένο τρόπο την έξοδο. Όσον αφορά την μεταβλητή \tl{waters}, επηρεάζει με συγκεκριμένο και συνεχή τρόπο την έξοδο. 

Στο τελευταίο μικρό σχήμα όπως και στο σχήμα  \ref{figure:111} έχουμε εποπτικά μία επιφάνεια που δείχνει πόσο επηρεάζουν οι μεταβλητές \tl{ngas} και \tl{load\_forecast} το \tl{SMP}. Ουσιαστικά δημιουργούνται περιοχές επηρεασμού της εξόδου, οι οποίες έχουν άμεση σχέση με την ζήτηση και την σημαντικότητα του φυσικού αερίου όπως περιγράψαμε.



































\newpage
\thispagestyle{empty}